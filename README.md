# pySpark

## O que é o Spark?
O Spark é um framework de processamento de dados, desenvolvido pela Apache Software Foundation, que oferece uma abordagem eficiente e escalável para lidar com grandes conjuntos de dados em tempo real e em lote.

A arquitetura distribuída do Spark permite executar tarefas complexas de processamento de dados em paralelo, aproveitando clusters (redes) de computadores para proporcionar velocidade e escalabilidade excepcionais.

## O que é o PySpark?
PySpark é a interface Python para o Spark, permitindo aos desenvolvedores escrever código Spark utilizando a linguagem de programação Python. Essa interface é essencial para muitos desenvolvedores e cientistas de dados, pois Python é uma linguagem popular e amplamente utilizada no domínio de análise de dados e aprendizado de máquina. A documentação do PySpark se encontra [aqui](https://spark.apache.org/docs/latest/api/python/index.html).

## Projeto

Manipulação, análise de dados e consultas SQL feitas em três arquivos CSV da receita federal. Os três arquivos CSV eram sobre empresas, estabelecimentos e sócios.

Você pode checar os códigos no Jupyter Notebook clicando [aqui](https://nbviewer.org/github/ViniciusBardelin/pySpark/blob/main/SparkNotebook.html). Além disso, os dados utilizados se encontram [aqui](https://drive.google.com/drive/folders/1FCSv1-ZhGJIjVwtM07yDA5H6_4bXVpET?usp=drive_link).
